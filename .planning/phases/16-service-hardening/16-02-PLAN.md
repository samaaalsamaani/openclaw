---
phase: 16-service-hardening
plan: 02
type: execute
wave: 1
depends_on:
  - 16-00
files_modified:
  - src/infra/memory-monitor.ts
  - src/infra/memory-monitor.test.ts
  - src/infra/circuit-breaker.ts
  - src/infra/circuit-breaker.test.ts
  - src/gateway/boot.ts
  - ~/.openclaw/projects/knowledge-base/embedding-server.py
autonomous: true
requirements:
  - SERV-01
  - SERV-03
  - SERV-04

must_haves:
  truths:
    - "Gateway memory usage is monitored every 60 seconds with growth rate tracking"
    - "Memory growth alerts appear in logs when heap grows >10MB/hour"
    - "Circuit breakers protect external MCP calls from cascading failures"
    - "Embedding server limits worker lifetime to 1000 requests (prevents unbounded memory growth)"
  artifacts:
    - path: "src/infra/memory-monitor.ts"
      provides: "Automated memory leak detection"
      exports: ["startMemoryMonitoring"]
    - path: "src/infra/circuit-breaker.ts"
      provides: "Circuit breaker state management"
      exports: ["CircuitBreaker"]
    - path: "~/.openclaw/projects/knowledge-base/embedding-server.py"
      provides: "FastAPI server with worker recycling"
      contains: "limit_max_requests"
  key_links:
    - from: "src/gateway/boot.ts"
      to: "src/infra/memory-monitor.ts"
      via: "startMemoryMonitoring() on Gateway startup"
      pattern: "startMemoryMonitoring"
    - from: "src/agents/sdk-runner/mcp-servers.ts"
      to: "src/infra/circuit-breaker.ts"
      via: "External API calls wrapped in circuit breaker"
      pattern: "CircuitBreaker"
---

<objective>
Detect and prevent memory leaks before they cause OOM crashes, and protect services from cascading failures via circuit breakers.

Purpose: Memory leaks accumulate slowly over days, eventually causing crashes. Automated monitoring detects growth patterns early. Circuit breakers prevent external service failures from taking down internal services.

Output:

- Memory monitoring module tracking heap growth with configurable thresholds
- Circuit breaker implementation for MCP external calls
- Embedding server configuration with worker recycling
  </objective>

<execution_context>
@/Users/user/.claude/get-shit-done/workflows/execute-plan.md
@/Users/user/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-service-hardening/16-CONTEXT.md
@.planning/phases/16-service-hardening/16-RESEARCH.md

# Test scaffolds from Wave 0

@src/infra/memory-monitor.test.ts — Pre-created test scaffold with todo markers
@src/infra/circuit-breaker.test.ts — Pre-created test scaffold with todo markers

# Gateway boot sequence

@src/gateway/boot.ts — Where to integrate memory monitoring startup

<interfaces>
<!-- Node.js memory monitoring API -->

From Node.js stdlib:

```typescript
interface MemoryUsage {
  rss: number;        // Resident set size
  heapTotal: number;  // Total heap allocated
  heapUsed: number;   // Heap actually used
  external: number;   // C++ objects bound to JS
  arrayBuffers: number;
}

function process.memoryUsage(): MemoryUsage;
```

Circuit Breaker States:

```typescript
type CircuitState = "closed" | "open" | "half-open";

interface CircuitBreakerOptions {
  failureThreshold: number; // Failures before opening
  timeoutMs: number; // How long to stay open
  monitorIntervalMs: number; // State check frequency
}
```

</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create memory monitoring module with heap growth detection</name>
  <files>
src/infra/memory-monitor.ts
src/infra/memory-monitor.test.ts
  </files>
  <action>
Create src/infra/memory-monitor.ts implementing:
1. startMemoryMonitoring() function that returns cleanup function (for graceful shutdown)
2. Check process.memoryUsage() every 60 seconds (MEMORY_CHECK_INTERVAL_MS = 60_000)
3. Track last 12 samples in circular buffer (memoryHistory: number[], 12 minutes of data)
4. Calculate growth rate: (newest - oldest) * (60 / window_size) = MB/hour
5. Alert if growth > 10MB/hour (MEMORY_GROWTH_THRESHOLD_MB = 10)
6. Log warning to console: `[memory-leak-warning] Heap growing ${rate.toFixed(1)} MB/hour`
7. Store interval in module-level variable, clear on cleanup()

Memory usage calculation:

```typescript
const usage = process.memoryUsage();
const heapUsedMB = Math.round(usage.heapUsed / 1048576); // bytes to MB
```

Flesh out src/infra/memory-monitor.test.ts (scaffold from Plan 16-00) by:

1. Converting it.todo() markers to full test implementations
2. Testing startMemoryMonitoring() returns cleanup function
3. Testing memory history tracks last 12 samples (FIFO)
4. Testing growth rate calculation is accurate (mock 12 samples with linear growth)
5. Testing no alert for growth <10MB/hour
6. Testing alert logged for growth >10MB/hour
7. Testing cleanup stops monitoring interval

Pattern: Implement module and tests simultaneously. Test scaffold from Plan 16-00 already defines the contract—fill in the test bodies while building the implementation.

Why 60-second interval: Balance between early detection and noise. Faster sampling creates false positives from GC cycles.

Why 12-minute window: Long enough to smooth GC spikes, short enough to detect real leaks within hours.
</action>
<verify>
<automated>pnpm test src/infra/memory-monitor.test.ts --run</automated>
</verify>
<done>Tests pass (all todo markers converted). Memory monitoring module exists, growth detection logic validated.</done>
</task>

<task type="auto">
  <name>Task 2: Create circuit breaker for external service calls</name>
  <files>
src/infra/circuit-breaker.ts
src/infra/circuit-breaker.test.ts
  </files>
  <action>
Create src/infra/circuit-breaker.ts implementing:
1. CircuitBreaker class with constructor(key: string, options: CircuitBreakerOptions)
2. State machine: closed (normal) → open (failing) → half-open (testing) → closed
3. execute<T>(fn: () => Promise<T>): Promise<T> method
4. Track failure count, last failure timestamp
5. State transitions:
   - closed → open: failures >= failureThreshold (default: 5)
   - open → half-open: elapsed time > timeoutMs (default: 60_000ms)
   - half-open → closed: single success
   - half-open → open: any failure
6. When open: immediately reject with error "Circuit breaker open for [key]"
7. On success in any state: reset failure count to 0

Export CircuitBreakerOptions interface and CircuitBreaker class.

Flesh out src/infra/circuit-breaker.test.ts (scaffold from Plan 16-00) by:

1. Converting it.todo() markers to full test implementations
2. Testing closed state allows calls through
3. Testing opens after 5 consecutive failures
4. Testing stays open for configured timeout
5. Testing half-open tries one call after timeout
6. Testing half-open → closed on success
7. Testing half-open → open on failure
8. Testing open state rejects immediately (no fn execution)

Pattern: Implement module and tests simultaneously. Test scaffold from Plan 16-00 already defines the contract—fill in the test bodies while building the implementation.

Why not use external library: Simple state machine (50 lines), no dependencies needed. Patterns are well-established from research.
</action>
<verify>
<automated>pnpm test src/infra/circuit-breaker.test.ts --run</automated>
</verify>
<done>Tests pass (all todo markers converted). Circuit breaker class exists, state transitions work correctly.</done>
</task>

<task type="auto">
  <name>Task 3: Integrate memory monitoring into Gateway and configure embedding server recycling</name>
  <files>
src/gateway/boot.ts
~/.openclaw/projects/knowledge-base/embedding-server.py
  </files>
  <action>
Update src/gateway/boot.ts:
1. Import startMemoryMonitoring from src/infra/memory-monitor.ts
2. Call startMemoryMonitoring() after server start (near end of boot sequence)
3. Store cleanup function in module-level variable
4. In existing shutdown handler, call memory monitor cleanup before process.exit()

Pattern: Start monitoring after all initialization complete, stop on shutdown.

Update ~/.openclaw/projects/knowledge-base/embedding-server.py:

1. Find uvicorn.run() call in **main** block
2. Add limit_max_requests=1000 parameter to uvicorn.run()
3. Add timeout_keep_alive=30 parameter
4. Add comment: "# Recycle worker after 1000 requests to prevent memory leaks"

Example:

```python
if __name__ == "__main__":
    uvicorn.run(
        app,
        host="127.0.0.1",
        port=11435,
        limit_max_requests=1000,  # Recycle worker after 1000 requests
        timeout_keep_alive=30
    )
```

Why limit_max_requests: Python ML models (sentence-transformers) have subtle memory leaks in underlying C++ libraries. Periodic worker recycling prevents unbounded growth.

Why 1000 requests: Balances memory safety (frequent recycling) with performance (avoid excessive worker churn). Based on FastAPI production hardening research.
</action>
<verify>
<automated>pnpm test src/gateway/boot.test.ts --run</automated>
<manual>Start Gateway, verify memory monitoring logs appear every 60 seconds</manual>
<manual>Check embedding-server.py for limit_max_requests parameter</manual>
</verify>
<done>Memory monitoring starts with Gateway, embedding server configured with worker recycling, both services have resource leak protection.</done>
</task>

</tasks>

<verification>
**Phase gate checks:**

1. Memory monitoring validation
   - Run: `pnpm test src/infra/memory-monitor.test.ts --run`
   - Expected: Growth detection works, cleanup stops monitoring

2. Circuit breaker state machine
   - Run: `pnpm test src/infra/circuit-breaker.test.ts --run`
   - Expected: All state transitions validated

3. Gateway integration
   - Run: `pnpm build && openclaw gateway start`
   - Expected: Memory monitoring logs appear every 60 seconds in Gateway logs

4. Embedding server configuration
   - Run: `cat ~/.openclaw/projects/knowledge-base/embedding-server.py | grep limit_max_requests`
   - Expected: limit_max_requests=1000 present

5. Type checking
   - Run: `pnpm check`
   - Expected: No TypeScript errors
     </verification>

<success_criteria>
**Observable outcomes:**

- Memory monitoring active in Gateway, logging heap usage every 60 seconds
- Memory growth alerts appear when heap increases >10MB/hour
- Circuit breaker protects against cascading failures (tested via unit tests)
- Embedding server limits worker lifetime to 1000 requests
- All tests pass, type checking clean
  </success_criteria>

<output>
After completion, create `.planning/phases/16-service-hardening/16-02-SUMMARY.md` documenting:
- Memory monitoring implementation and threshold tuning
- Circuit breaker pattern and state transitions
- Embedding server worker recycling configuration
- Integration points in Gateway boot sequence
</output>
